# Implemented Algorithms In MALib

## Population-based Learning Algorithms

- [x] PSRO: Lanctot, Marc, et al. "A unified game-theoretic approach to multiagent reinforcement learning." Advances in neural information processing systems 30 (2017). [[arXiv](https://arxiv.org/pdf/1711.00832.pdf)] | [[official code](https://github.com/deepmind/open_spiel)]
- [ ] P2SRO: McAleer, Stephen, et al. "Pipeline psro: A scalable approach for finding approximate nash equilibria in large games." Advances in neural information processing systems 33 (2020): 20238-20248. [[arXiv](https://proceedings.neurips.cc/paper/2020/file/e9bcd1b063077573285ae1a41025f5dc-Paper.pdf)] | [[official code](https://github.com/JBLanier/pipeline-psro)]
- [ ] EPSRO: Zhou, Ming, et al. "Efficient Policy Space Response Oracles." arXiv preprint arXiv:2202.00633 (2022). [[arXiv](https://arxiv.org/pdf/2202.00633)] | [offcial code]
- [ ] ODO: Dinh, Le Cong, et al. "Online Double Oracle." arXiv preprint arXiv:2103.07780 (2021). [[arXiv](https://arxiv.org/abs/2103.07780)] | [[official code](https://github.com/npvoid/OnlineDoubleOracle)]
- [ ] XDO: McAleer, Stephen, et al. "XDO: A double oracle algorithm for extensive-form games." Advances in Neural Information Processing Systems 34 (2021): 23128-23139. [[arXiv](https://proceedings.neurips.cc/paper/2021/file/c2e06e9a80370952f6ec5463c77cbace-Paper.pdf)] | [[official code](https://github.com/indylab/nxdo)]
- [ ] NeurPL: Liu, Siqi, et al. "NeuPL: Neural Population Learning." International Conference on Learning Representations. 2021. [[arXiv](https://arxiv.org/abs/2202.07415)] | [official code]

## Multi-agent Reinforcement Learning Algorithms

- [x] MADDPG: Lowe, Ryan, et al. "Multi-agent actor-critic for mixed cooperative-competitive environments." Advances in neural information processing systems 30 (2017). [[arXiv](https://arxiv.org/abs/1706.02275)]
- [x] MAPPO: Yu, Chao, et al. "The surprising effectiveness of ppo in cooperative, multi-agent games." arXiv preprint arXiv:2103.01955 (2021). [[arXiv](https://arxiv.org/abs/2103.01955)]
- [x] QMIX: Rashid, Tabish, et al. "Qmix: Monotonic value function factorisation for deep multi-agent reinforcement learning." International conference on machine learning. PMLR, 2018. [[arXiv](http://proceedings.mlr.press/v80/rashid18a/rashid18a.pdf)]

## Single-agent Reinforcement Learning Algorithms
- [x] A3C: Mnih, Volodymyr, et al. "Asynchronous methods for deep reinforcement learning." International conference on machine learning. PMLR, 2016. [[arXiv](https://arxiv.org/pdf/1602.01783.pdf)]
- [x] DDPG: Lillicrap, Timothy P., et al. "Continuous control with deep reinforcement learning." arXiv preprint arXiv:1509.02971 (2015). [[arXiv](https://arxiv.org/abs/1509.02971)]
- [x] SAC: Haarnoja, Tuomas, et al. "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor." International conference on machine learning. PMLR, 2018. [[arXiv](https://arxiv.org/abs/1801.01290)]
- [x] DQN: Mnih, Volodymyr, et al. "Human-level control through deep reinforcement learning." nature 518.7540 (2015): 529-533. [[arXiv](https://arxiv.org/abs/1312.5602)]
- [x] PG: Sutton, Richard S., et al. "Policy gradient methods for reinforcement learning with function approximation." Advances in neural information processing systems 12 (1999). [[arXiv](https://proceedings.neurips.cc/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf)]
- [x] PPO: Schulman, John, et al. "Proximal policy optimization algorithms." arXiv preprint arXiv:1707.06347 (2017). [[arXiv](https://arxiv.org/abs/1707.06347)]
