# # battle: https://github.com/wsjeon/maddpg-rllib
# group: "Gym"
# name: "share/bc_pendulum"

# training:
#   interface:
#     type: "independent"
#     population_size: -1
#   config:
#     # control the frequency of remote parameter update
#     batch_size: 512
#     optimizer: "Adam"
#     lr: 0.01
#     grad_norm_clipping: 2.0
#     stopper: "simple_training"
#     stopper_config:
#       max_step: 10000

# rollout:
#   type: "async"
#   stopper: "none"
#   metric_type: "simple"
#   fragment_length: 200
#   num_episodes: 5
#   episode_seg: 1
#   terminate: "any"
#   callback: "simultaneous"
#   save_model: False

# env_description:
#   creator: "Gym"
#   config:
#     env_id: "Pendulum-v0"

# algorithms:
#   BC:
#     name: "BC"
#     model_config:
#       actor:
#         network: mlp
#         layers:
#           - units: 64
#             activation: ReLU
#           - units: 64
#             activation: ReLU
#         output:
#           type: "gaussian"
#           activation: False

# global_evaluator:
#   name: "generic"

# dataset_config:
#   episode_capacity: 100000
#   extern:
#     links:
#       - name: "expert_data"
#         path: "demos/Pendulum-v0/DDPG"
#         write: False
#     sample_rates: [1]
